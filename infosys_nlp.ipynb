{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968937ed-9215-42fc-a1ba-fe59403f63f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared: 400 train, 100 test.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "CSV_PATH = \"education_policies.csv\"\n",
    "TRAIN_PATH = \"train_policies.csv\"\n",
    "TEST_PATH = \"test_policies.csv\"\n",
    "\n",
    "def generate_synthetic_policies(n=500):\n",
    "    states = [\"Karnataka\",\"Maharashtra\",\"Tamil Nadu\",\"Uttar Pradesh\",\"Delhi\",\"Kerala\",\"West Bengal\",\"Gujarat\",\"Rajasthan\",\"Punjab\"]\n",
    "    sectors = [\"Primary\",\"Secondary\",\"Higher Education\",\"Vocational\",\"Early Childhood\"]\n",
    "    target_groups = [\"Students\",\"Teachers\",\"Rural Students\",\"Urban Students\",\"Women\",\"Disadvantaged Groups\",\"All\"]\n",
    "    statuses = [\"Proposed\",\"Implemented\",\"Under Review\",\"Pilot\"]\n",
    "    years = list(range(2015, 2026))\n",
    "    stakeholders_list = [\n",
    "        \"Ministry of Education, Local NGOs\",\n",
    "        \"State Education Department, Private Partners\",\n",
    "        \"Teachers' Unions, Community Leaders\",\n",
    "        \"Central Government, Donors\",\n",
    "        \"EdTech Companies, Universities\"\n",
    "    ]\n",
    "    funding_ranges = [(0.5,5),(5,20),(20,100),(0.1,0.5)]\n",
    "    aspects = [\"learning outcomes\",\"infrastructure\",\"teacher quality\",\"digital access\",\"early childhood development\",\"vocational skills\"]\n",
    "    interventions = [\"grants to schools\",\"teacher training programs\",\"digital device distribution\",\"curriculum reform\",\"scholarship schemes\",\"public-private partnerships\"]\n",
    "    focuses = [\"marginalized communities\",\"gender equity\",\"rural accessibility\",\"urban inclusion\",\"STEM education\",\"literacy and numeracy\"]\n",
    "    secondary_aspects = [\"community participation\",\"governance\",\"assessment quality\",\"safety standards\"]\n",
    "\n",
    "    records = []\n",
    "    for i in range(1, n+1):\n",
    "        policy_id = f\"P{1000+i}\"\n",
    "        title = f\"{random.choice(['National','State','District'])} {random.choice(sectors)} Education Reform {random.randint(1,99)}\"\n",
    "        sector = random.choice(sectors)\n",
    "        region = random.choice(states)\n",
    "        year = random.choice(years)\n",
    "        target_group = random.choice(target_groups)\n",
    "        status = random.choice(statuses)\n",
    "        funding = round(random.uniform(*random.choice(funding_ranges)), 2)\n",
    "        stakeholders = random.choice(stakeholders_list)\n",
    "        impact_score = round(random.uniform(0.1, 0.99), 3)\n",
    "        summary = f\"This policy aims to improve {random.choice(aspects)} in {sector} through {random.choice(interventions)} in {region}.\"\n",
    "        goals = f\"Increase reach by {random.randint(5,40)}% in {random.randint(1,5)} years.\"\n",
    "        full_text = f\"{summary} Goals: {goals}\"\n",
    "\n",
    "        records.append({\n",
    "            \"policy_id\": policy_id,\n",
    "            \"title\": title,\n",
    "            \"sector\": sector,\n",
    "            \"region\": region,\n",
    "            \"year\": year,\n",
    "            \"target_group\": target_group,\n",
    "            \"status\": status,\n",
    "            \"funding_million_usd\": funding,\n",
    "            \"stakeholders\": stakeholders,\n",
    "            \"impact_score\": impact_score,\n",
    "            \"summary\": summary,\n",
    "            \"goals\": goals,\n",
    "            \"full_text\": full_text\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df[\"text_for_nlp\"] = (df[\"title\"].astype(str) + \". \" + df[\"full_text\"].astype(str) + \". Stakeholders: \" + df[\"stakeholders\"].astype(str)).str.lower()\n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    df = generate_synthetic_policies(500)\n",
    "    df.to_csv(CSV_PATH, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Preprocess and split\n",
    "df = preprocess(df)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)\n",
    "\n",
    "train_df.to_csv(TRAIN_PATH, index=False)\n",
    "test_df.to_csv(TEST_PATH, index=False)\n",
    "\n",
    "print(f\"Data prepared: {len(train_df)} train, {len(test_df)} test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0925ef8d-56d9-440c-9deb-58b57b6c143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bb4be7-0216-428c-93fd-e7a63cd4af00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model trained and saved to policy_vectorizer.pkl and policy_tfidf_matrix.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "MODEL_PATH = \"policy_vectorizer.pkl\"\n",
    "MATRIX_PATH = \"policy_tfidf_matrix.pkl\"\n",
    "\n",
    "# Load train and full dataset\n",
    "train_df = pd.read_csv(\"train_policies.csv\") #  read the dataset \n",
    "full_df = pd.read_csv(\"education_policies.csv\")\n",
    "\n",
    "# --- FIX: Preprocess full_df so it has \"text_for_nlp\" ---\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df[\"text_for_nlp\"] = (df[\"title\"].astype(str) + \". \" +\n",
    "                          df[\"full_text\"].astype(str) + \". Stakeholders: \" +\n",
    "                          df[\"stakeholders\"].astype(str)).str.lower()\n",
    "    return df\n",
    "\n",
    "train_df = preprocess(train_df)\n",
    "full_df = preprocess(full_df)\n",
    "\n",
    "# Train TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2)) # model \n",
    "\n",
    "vectorizer.fit(train_df[\"text_for_nlp\"]) # training \n",
    "\n",
    "# Transform full data\n",
    "tfidf_matrix = vectorizer.transform(full_df[\"text_for_nlp\"]) \n",
    "\n",
    "# Save model + matrix\n",
    "joblib.dump(vectorizer, MODEL_PATH)\n",
    "joblib.dump({\"matrix\": tfidf_matrix, \"df\": full_df}, MATRIX_PATH)\n",
    "\n",
    "print(f\"âœ… Model trained and saved to {MODEL_PATH} and {MATRIX_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fcd641-a7c1-441c-81f7-2f1b42fd0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# --------------------------\n",
    "# 1. Sparsity\n",
    "# --------------------------\n",
    "sparsity = 100.0 * (tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1]))\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}, Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "# --------------------------\n",
    "# 2. Top 20 words in vocabulary\n",
    "# --------------------------\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "# Sum over all documents to get overall importance\n",
    "tfidf_sum = np.array(tfidf_matrix.sum(axis=0)).flatten()\n",
    "top_indices = tfidf_sum.argsort()[::-1][:20]\n",
    "print(\"Top 20 words/phrases by TF-IDF importance:\")\n",
    "for word, score in zip(feature_names[top_indices], tfidf_sum[top_indices]):\n",
    "    print(f\"{word}: {score:.2f}\")\n",
    "\n",
    "# --------------------------\n",
    "# 3. PCA projection (2D) of documents\n",
    "# --------------------------\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(tfidf_matrix.toarray())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(reduced[:,0], reduced[:,1], alpha=0.6)\n",
    "plt.title(\"PCA Projection of TF-IDF Document Vectors\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# 4. Optional: Word cloud of top words\n",
    "# --------------------------\n",
    "top_words_dict = {feature_names[i]: tfidf_sum[i] for i in range(len(feature_names))}\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top_words_dict)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"TF-IDF Word Cloud of Top Terms\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266eb147-8e64-4010-a617-249be48bfdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f32f26-f8ea-4daf-b99a-a356c0830cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0762c996-888a-44f5-a0e0-4d347ae4154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8fcdf7-571e-49c5-a5ef-cb8ed69d81ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Query: teacher training and capacity building initiatives\n",
      "\n",
      "ðŸ“Œ National Primary Education Reform 6 (P1003) | Score=0.295\n",
      "Region: Delhi | Year: 2016 | Status: Implemented\n",
      "Summary: Policy to enhance teacher quality and assessment quality using teacher training programs. Includes capacity-building, monitoring and community engagement. Goals: Introduce technology-enabled platforms for learning continuity, improve assessment...\n",
      "\n",
      "ðŸ“Œ State Higher Education Education Reform 76 (P1316) | Score=0.282\n",
      "Region: Gujarat | Year: 2023 | Status: Proposed\n",
      "Summary: Policy to enhance teacher quality and safety standards using teacher training programs. Includes capacity-building, monitoring and community engagement. Goals: Introduce technology-enabled platforms for learning continuity, improve assessment...\n",
      "\n",
      "ðŸ“Œ State Early Childhood Education Reform 66 (P1372) | Score=0.279\n",
      "Region: Maharashtra | Year: 2019 | Status: Proposed\n",
      "Summary: Policy to enhance teacher quality and assessment quality using teacher training programs. Includes capacity-building, monitoring and community engagement. Goals: Introduce technology-enabled platforms for learning continuity, improve assessment...\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "MODEL_PATH = \"policy_vectorizer.pkl\"\n",
    "MATRIX_PATH = \"policy_tfidf_matrix.pkl\"\n",
    "\n",
    "vectorizer = joblib.load(MODEL_PATH)\n",
    "\n",
    "data = joblib.load(MATRIX_PATH) \n",
    "\n",
    "\n",
    "tfidf_matrix = data[\"matrix\"]\n",
    "df = data[\"df\"]\n",
    "\n",
    "def answer_query(query, top_k=3):\n",
    "    query_vec = vectorizer.transform([query.lower()])\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    top_idx = sims.argsort()[::-1][:top_k]\n",
    "\n",
    "    print(f\"\\nðŸ”Ž Query: {query}\")\n",
    "    for idx in top_idx:\n",
    "        row = df.iloc[idx]\n",
    "        snippet = textwrap.shorten(row[\"full_text\"], width=250, placeholder=\"...\")\n",
    "        print(f\"\\nðŸ“Œ {row['title']} ({row['policy_id']}) | Score={sims[idx]:.3f}\")\n",
    "        print(f\"Region: {row['region']} | Year: {row['year']} | Status: {row['status']}\")\n",
    "        print(f\"Summary: {snippet}\")\n",
    "\n",
    "# Example query\n",
    "answer_query(\"teacher training and capacity building initiatives\", top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2d67ee-c93e-4f3b-a285-f70b2d3d4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. District Early Childhood Education Reform 85 (Stakeholders: EdTech Companies, Universities, Similarity: 0.23)\n",
      "2. National Secondary Education Reform 61 (Stakeholders: State Education Department, Private Partners, Similarity: 0.19)\n",
      "3. State Vocational Education Reform 99 (Stakeholders: EdTech Companies, Universities, Similarity: 0.18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load saved models\n",
    "vectorizer = joblib.load(\"policy_vectorizer.pkl\")\n",
    "data = joblib.load(\"policy_tfidf_matrix.pkl\")\n",
    "tfidf_matrix = data[\"matrix\"]\n",
    "full_df = data[\"df\"]\n",
    "\n",
    "# --------------------------\n",
    "# Query function\n",
    "# --------------------------\n",
    "def query_policy(question, top_k=3):\n",
    "    \"\"\"\n",
    "    Returns top_k matching policies for the input question/query.\n",
    "    \"\"\"\n",
    "    # Preprocess the query similarly\n",
    "    query_text = question.lower()\n",
    "    \n",
    "    # Vectorize\n",
    "    query_vec = vectorizer.transform([query_text])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Get top k indices\n",
    "    top_indices = sims.argsort()[::-1][:top_k]\n",
    "    \n",
    "    # Return policy info\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        row = full_df.iloc[idx]\n",
    "        results.append({\n",
    "            \"title\": row[\"title\"],\n",
    "            \"stakeholders\": row[\"stakeholders\"],\n",
    "            \"similarity\": float(sims[idx])\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------------\n",
    "# Demo usage\n",
    "# --------------------------\n",
    "question = \"How are teacher trainings implemented in rural schools?\"\n",
    "top_matches = query_policy(question, top_k=3)\n",
    "\n",
    "for i, res in enumerate(top_matches, 1):\n",
    "    print(f\"{i}. {res['title']} (Stakeholders: {res['stakeholders']}, Similarity: {res['similarity']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2571753-6f35-4820-b2c8-13db821c82c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
